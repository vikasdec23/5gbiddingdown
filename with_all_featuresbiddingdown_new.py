# -*- coding: utf-8 -*-
"""with_all_featuresBiddingdown_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZbBI4VE3uSaD1LLujGJspNFwrdwF46xj
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
dataset_df = pd.read_csv('/content/Dataset collection_biddingdown attack - Sheet17.csv')

column=["Date","Time","Latitude","Longitude","Connectivity","BAND","POWER (nW)","ASU","PING (in ms)","JITTER (in ms)","DL (in Mbps)","UL (in Mbps)","RSSI","RSRQ","RSRP","RXLEV"]
dataset_df.head()
dataset_df.size
dataset_df.shape
dataset_df.count()
dataset_df.info()
print(column)

dataset_df['Connectivity'].value_counts()

dataset_df['POWER (nW)'] = dataset_df['POWER (nW)'].astype(float, errors = 'raise')

column=["Date","Time","Latitude","Longitude","Connectivity","BAND","POWER (nW)","ASU","PING (in ms)","JITTER (in ms)","DL (in Mbps)","UL (in Mbps)","RSSI","RSRQ","RSRP","RXLEV"]
dataset_df.head()
dataset_df.size
dataset_df.shape
dataset_df.count()
dataset_df.info()

import seaborn as sns
import matplotlib.pyplot as plt
sns.set_theme(style="ticks", color_codes=True)

#data1 = sns.load_dataset("dataset") compactness_worst,concavity_worst, concave points_worst, symmetry_worst, fractal_dimension_worst
sns.catplot(x="Connectivity", y="UL (in Mbps)", kind="swarm",data=dataset_df)
sns.catplot(x="Connectivity", y="DL (in Mbps)", kind="swarm", data=dataset_df)
sns.catplot(x="Connectivity", y="PING (in ms)",kind="swarm", data=dataset_df)
sns.catplot(x="Connectivity", y="JITTER (in ms)", kind="swarm",data=dataset_df)
#sns.jointplot(x=dataset_df['Connectivity'], y=dataset_df['UL (in Mbps)']);
#f, axes = plt.subplots(2, 3,figsize=(15, 5))
#sns.boxplot(  x="Connectivity", y="UL (in Mbps)", data=dataset_df)

print(dataset_df.columns)
#mask = np.zeros_like(df[columns].corr(),dtype=np.bool)
mask = np.zeros_like(dataset_df.corr(),dtype=np.bool)
mask[np.triu_indices_from(mask)]=True

f, ax = plt.subplots(figsize=(8, 8))
plt.title('Pearson Correlation Matrix',fontsize=23)

sns.heatmap(dataset_df[column].corr(),linewidths=0.25, vmax=1.0, square=True, cmap="BuGn",
            linecolor='w', annot=True, mask=mask, cbar_kws={"shrink": .75})

f.tight_layout()

column1=["Connectivity","POWER (nW)","ASU","PING (in ms)","JITTER (in ms)","DL (in Mbps)","UL (in Mbps)"]
mask = np.zeros_like(dataset_df[column1].corr(),dtype=np.bool)
#mask = np.zeros_like(dataset_df.corr(),dtype=np.bool)
mask[np.triu_indices_from(mask)]=True

f, ax = plt.subplots(figsize=(8, 8))
plt.title('Pearson Correlation Matrix',fontsize=23)

sns.heatmap(dataset_df[column1].corr(),linewidths=0.25, vmax=1.0, square=True, cmap="BuGn",
            linecolor='w', annot=True, mask=mask, cbar_kws={"shrink": .75})

f.tight_layout()

dataset_df.dtypes
dataset_df.columns
feature_df = dataset_df[column1]
X=np.asarray(feature_df)
y=np.asarray(dataset_df['Connectivity'])
y.shape
y[0:5]

#column1=["Connectivity","POWER (nW)","ASU","PING (in ms)","JITTER (in ms)","DL (in Mbps)","UL (in Mbps)"]
column2=["Connectivity","ASU","PING (in ms)","JITTER (in ms)","DL (in Mbps)","UL (in Mbps)"]
feature_df=dataset_df[column2]
y = feature_df['Connectivity']
X = feature_df.drop('Connectivity', axis = 1)
#X = X.drop('Unnamed: 32', axis = 1)
#X = X.drop('id', axis = 1)
# Separating the dependent and independent variable

X_train, X_test, y_train, y_test = train_test_split(
			X, y, test_size = 0.3, random_state = 0)
# Splitting the data into training and testing data
print(X)

#Import svm package from sklearn
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred_svm = clf.predict(X_test)


from sklearn.metrics import classification_report

print("#####classification_report svm linear#####",'\n')
print(classification_report(y_test,y_pred_svm))

import pickle
with open('model.pkl','wb') as f:
    pickle.dump(classifier, f)
with open('model.pkl','rb') as f:
    classifier_loaded = pickle.load(f)

#from sklearn.model_selection import train_test_split
#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)
#y_test.shape
#X_train.shape
#from sklearn import svm
#classifier=svm.SVC(kernel = 'linear',gamma='auto',C=2)
#classifier.fit(X_train,y_train)
#y_predict = classifier.predict(X_test)
#from sklearn.metrics import classification_report
#print(classification_report(y_test,y_predict))
#from sklearn.metrics import accuracy_score
#print(accuracy_score(y_test,y_predict))
#import pickle
#with open('model.pkl','wb') as f:
#    pickle.dump(classifier, f)
#with open('model.pkl','rb') as f:
 #   classifier_loaded = pickle.load(f)